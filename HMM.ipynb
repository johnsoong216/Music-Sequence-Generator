{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from numpy import linspace,exp\n",
    "from numpy.random import randn\n",
    "# import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "# import seaborn as sns\n",
    "\n",
    "import scipy \n",
    "import editdistance\n",
    "import sklearn.metrics\n",
    "import statsmodels.api as sm\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Convert the loaded JSB_Chorales into the a list of singular notes to match format of midi notes.\n",
    "def get_training_notes(dataset):\n",
    "    notes=[]\n",
    "    current_notes=[]   \n",
    "    \n",
    "    for piece in dataset['train']:\n",
    "        for seq in piece:\n",
    "            unwanted=[]\n",
    "            for i in current_notes:\n",
    "                if i not in list(seq):\n",
    "                    notes.append(i)\n",
    "                    unwanted.append(i)\n",
    "            current_notes = [ele for ele in current_notes if ele not in unwanted] \n",
    "\n",
    "            for j in list(seq):\n",
    "                if j not in current_notes:\n",
    "                    notes.append(j)\n",
    "                    current_notes.append(j)\n",
    "    return notes      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_vel(newNotes, velocity,gp):\n",
    "    # Use splines to interpolate the velocities\n",
    "    newVelocities = np.zeros(len(newNotes))\n",
    "    y = velocity[np.nonzero(velocity)] # all the nonzero elements need to be interpolated\n",
    "    indicies = []\n",
    "    for i in np.unique(newNotes):\n",
    "        indicies.append(np.where(newNotes == i)[0][::2])  ## set every other pitch occurrence to 0 (turn off)\n",
    "   \n",
    "    unlist = [item for sublist in indicies for item in sublist]\n",
    "    unlist.sort()\n",
    "    \n",
    "    X = np.array(range(0,len(y)))\n",
    "    s = UnivariateSpline(X, y, s=300) #750\n",
    "    xs = np.linspace(0, len(y), len(unlist), endpoint = True)\n",
    "    ys = s(xs)   \n",
    "    newVelocities[np.array(unlist)] = np.round(ys).astype(int)\n",
    "    #Fix entries that are too small or too large due to spline overfitting\n",
    "    newVelocities[np.where(newVelocities < 0)[0]] = y[-1]\n",
    "    #print(y[-1])\n",
    "    newVelocities = newVelocities.astype(int)     \n",
    "    return(newVelocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pre_process(object):\n",
    "    def __init__(self, input_filename, min_note):\n",
    "        self.input_filename = input_filename\n",
    "        self.min_note = min_note\n",
    "      \n",
    "    \n",
    "    def read_process(self):\n",
    "        with open(self.input_filename,encoding = \"ISO-8859-1\") as fd:\n",
    "            reader=csv.reader(fd)\n",
    "            rows= [row for idx, row in enumerate(reader)]\n",
    "        song = pd.DataFrame(rows)\n",
    "        r,c = np.where(song == ' Header')\n",
    "        quarter_note = song.iloc[r,5].values.astype(int)[0]\n",
    "        r, c = np.where(song == ' Time_signature')\n",
    "        num = song.iloc[r, 3].values.astype(int)[0]\n",
    "        denom = song.iloc[r, 4].values.astype(int)[0]**2\n",
    "        try:\n",
    "            r, c = np.where(song == ' Key_signature')\n",
    "            key = song.iloc[r,3].values.astype(int)[0]\n",
    "        except:\n",
    "            key = None\n",
    "        \n",
    "        song_model = song[song.iloc[:, 2].isin([' Note_on_c', ' Note_off_c'])]\n",
    "        song_model = song_model.loc[song_model.iloc[:,0] == np.max(song_model.iloc[:,0])]\n",
    "        \n",
    "        time = np.array(song_model.iloc[:,1]).astype(int)\n",
    "        notes = np.array(song_model.iloc[:,4]).astype(int)\n",
    "        velocity = np.array(song_model.iloc[:,5]).astype(int)\n",
    "        measures = np.round(np.max(time)/quarter_note)/num\n",
    "        min_note = quarter_note\n",
    "        actual = np.arange(0, min_note*measures*num, min_note).astype(int) \n",
    "        time = np.array([find_nearest(actual, time[i]) for i in range(len(time))]).astype(int)\n",
    "        return (quarter_note, num, denom, key, measures, time, notes, velocity, song, song_model.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "## Convert from pitch representation (integers 0-127) to integers (0-max)\n",
    "## x is the input vector of notes and code is a vector of the unique pitches in x\n",
    "class LabelEncoderDecoder():\n",
    "    def __init__(self, x):\n",
    "        self.processor = preprocessing.LabelEncoder()\n",
    "        self.processor.fit(x)\n",
    "        \n",
    "    def encode(self, y):\n",
    "        return self.processor.transform(y)\n",
    "    \n",
    "    def decode(self, y):\n",
    "        return self.processor.inverse_transform(y)\n",
    "    \n",
    "    def all_classes(self):\n",
    "        return self.processor.classes_\n",
    "    \n",
    "    def all_encode_classes(self):\n",
    "        return self.encode(self.all_classes())\n",
    "    \n",
    "    def max_encode_class(self):\n",
    "        return max(self.all_encode_classes())\n",
    "    \n",
    "\n",
    "## Function to convert the values in array to the nearest values in the array value\n",
    "## Used to convert continues TVAR generated pitches to closest integer values for MIDI representation\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_music_csv(output_filename,time,newNotes,newVelocities):\n",
    "    song.iloc[ind, 1] = time\n",
    "    song.iloc[ind, 4] = newNotes\n",
    "    song.iloc[ind, 5] = newVelocities\n",
    "    song.iloc[ind[np.where(newVelocities !=0)], 2] = ' Note_on_c'\n",
    "    song.iloc[ind[np.where(newVelocities ==0)], 2] = ' Note_off_c'\n",
    "    split = output_filename.split('.')\n",
    "    song.to_csv(output_filename, header = None, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_base(model, n):\n",
    "    start_prob = model.startprob_\n",
    "    transmat = model.transmat_\n",
    "    emissionprob = model.emissionprob_\n",
    "    m = transmat.shape[0]\n",
    "    k = emissionprob.shape[1]\n",
    "    zstates = np.arange(0, m, dtype = int)\n",
    "    xstates = np.arange(0, k, dtype = int)\n",
    "    z = np.zeros(n, dtype = int)\n",
    "    x = np.zeros(n, dtype = int)\n",
    "    z[0] = np.random.choice(zstates, size = 1, p = start_prob)\n",
    "    for j in range(1, n):\n",
    "        z[j] = np.random.choice(zstates, size = 1, p = transmat[z[j-1], :])\n",
    "    for i in range(0, n):\n",
    "        x[i] = np.random.choice(xstates, size = 1, p = emissionprob[z[i], :])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_layered(emissionprob1, emissionprob2, emissionprob3, zStar3, n):\n",
    "    m = emissionprob1.shape[0]\n",
    "    k = emissionprob1.shape[1]\n",
    "    zstates = np.arange(0, m, dtype = int)\n",
    "    xstates = np.arange(0, k, dtype = int)\n",
    "    output = np.zeros(shape = (3,n), dtype = int)\n",
    "    for j in range(0,n):\n",
    "        output[2, j] = np.random.choice(zstates, size = 1, p = emissionprob3[zStar3[j], :])\n",
    "        output[1, j] = np.random.choice(zstates, size = 1, p = emissionprob2[output[2, j], :])\n",
    "        output[0, j] = np.random.choice(xstates, size = 1, p = emissionprob1[output[1, j], :])\n",
    "    return output[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output_interpolate(model1, model2, n, gamma, leds):\n",
    "    state_num = model1.emissionprob_.shape[0]\n",
    "    start_prob = model1.startprob_ * gamma + model2.startprob_ * (1-gamma)\n",
    "    transmat = model1.transmat_ * gamma + model2.transmat_ * (1-gamma)\n",
    "    specific = leds[0].decode(np.arange(model1.emissionprob_.shape[1]))\n",
    "    generic = leds[1].decode(np.arange(model2.emissionprob_.shape[1]))\n",
    "    emissionprob = np.zeros([state_num, leds[2].max_encode_class() + 1])\n",
    "    print(emissionprob.shape)\n",
    "    for j in range(len(specific)):\n",
    "        col = leds[2].encode([specific[j]])[0]\n",
    "        emissionprob[:, col] += gamma * model1.emissionprob_[:, j]\n",
    "    for j in range(len(generic)):\n",
    "        col = leds[2].encode([generic[j]])[0]\n",
    "        emissionprob[:, col] += (1-gamma) * model2.emissionprob_[:, j]\n",
    "        \n",
    "    m = transmat.shape[0]\n",
    "    k = emissionprob.shape[1]\n",
    "    zstates = np.arange(0, m, dtype = int)\n",
    "    xstates = np.arange(0, k, dtype = int)\n",
    "    z = np.zeros(n, dtype = int)\n",
    "    x = np.zeros(n, dtype = int)\n",
    "    z[0] = np.random.choice(zstates, size = 1, p = start_prob)\n",
    "    for j in range(1, n):\n",
    "        z[j] = np.random.choice(zstates, size = 1, p = transmat[z[j-1], :])\n",
    "    for i in range(0, n):\n",
    "        x[i] = np.random.choice(xstates, size = 1, p = emissionprob[z[i], :])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Base HMM</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to Midi\n",
    "import py_midicsv\n",
    "\n",
    "\n",
    "# Save the parsed MIDI file to disk\n",
    "with open(dir_path+fname+'_hmm_layered'+str(states)+\".midi\", \"wb\") as output_file:\n",
    "    midi_writer = py_midicsv.FileWriter(output_file)\n",
    "    midi_writer.write(midi_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Choose a music template\n",
    "fname = 'twinkle-twinkle-little-star'\n",
    "min_note = 1024\n",
    "\n",
    "# load music template from midi file\n",
    "dir_path = './data/'\n",
    "filepath = os.path.join(dir_path,fname+'.csv')\n",
    "music = pre_process(filepath,min_note)\n",
    "\n",
    "# Obtain all components of a midi piano file\n",
    "quarter_note, num, denom, key, measures, time, \\\n",
    "            notes_template, velocity, song, ind = music.read_process()\n",
    "possibleVelocities =  np.unique(velocity)\n",
    "\n",
    "tr_notes = notes_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = set()\n",
    "a.add(1)\n",
    "b = set()\n",
    "b.add(2)\n",
    "a.union(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/chopin_hmm10.csv\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training data\n",
    "possibleNotes = np.unique(tr_notes)\n",
    "k = len(possibleNotes)\n",
    "led = LabelEncoderDecoder(tr_notes)\n",
    "xNotes = led.encode(tr_notes)\n",
    "n = len(xNotes)\n",
    "states = 10\n",
    "\n",
    "# Train with HMM\n",
    "model = hmm.MultinomialHMM(n_components=states)\n",
    "observ_data = xNotes.reshape(len(xNotes),1)\n",
    "model.fit(observ_data)\n",
    "newNotes = led.decode(generate_output_base(model, len(notes_template)))\n",
    "newVelocities = find_vel(newNotes, velocity, gp = False)\n",
    "\n",
    "# Output music into csv \n",
    "output_filename = dir_path+fname+'_hmm'+str(states)+'.csv'\n",
    "print(output_filename)\n",
    "output_music_csv(output_filename,time,newNotes.astype(int),newVelocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to Midi\n",
    "import py_midicsv\n",
    "\n",
    "with open(output_filename, \"r\") as f:\n",
    "    midi_object = py_midicsv.csv_to_midi(f.readlines())\n",
    "\n",
    "# Save the parsed MIDI file to disk\n",
    "with open(dir_path+fname+'_hmm'+str(states)+\".midi\", \"wb\") as output_file:\n",
    "    midi_writer = py_midicsv.FileWriter(output_file)\n",
    "    midi_writer.write(midi_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Layered HMM </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.MultinomialHMM(n_components=states)\n",
    "observ_data = xNotes.reshape(len(xNotes),1)\n",
    "model.fit(observ_data)\n",
    "zStar1 = model.predict(observ_data).astype(int)\n",
    "emissionprob1 = model.emissionprob_\n",
    "\n",
    "model2 = hmm.MultinomialHMM(n_components=states)\n",
    "observ_data = zStar1.reshape(len(zStar1),1)\n",
    "model2.fit(observ_data)\n",
    "zStar2 = model2.predict(observ_data).astype(int)\n",
    "emissionprob2 = model2.emissionprob_\n",
    "\n",
    "model3 = hmm.MultinomialHMM(n_components=states)\n",
    "observ_data = zStar2.reshape(len(zStar2),1)\n",
    "model3.fit(observ_data)\n",
    "zStar3 = model3.predict(observ_data).astype(int)\n",
    "emissionprob3 = model3.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/chopin_hmm_layered10.csv\n"
     ]
    }
   ],
   "source": [
    "newNotes = led.decode(generate_output_layered(emissionprob1, emissionprob2, emissionprob3, zStar3, n))\n",
    "newVelocities = find_vel(newNotes, velocity, gp = False)\n",
    "\n",
    "# Output music into csv \n",
    "output_filename = dir_path+fname+'_hmm_layered'+str(states)+'.csv'\n",
    "print(output_filename)\n",
    "output_music_csv(output_filename,time,newNotes.astype(int),newVelocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to Midi\n",
    "import py_midicsv\n",
    "\n",
    "with open(output_filename, \"r\") as f:\n",
    "    midi_object = py_midicsv.csv_to_midi(f.readlines())\n",
    "\n",
    "# Save the parsed MIDI file to disk\n",
    "with open(dir_path+fname+'_hmm_layered'+str(states)+\".midi\", \"wb\") as output_file:\n",
    "    midi_writer = py_midicsv.FileWriter(output_file)\n",
    "    midi_writer.write(midi_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> HMM Interpolation </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting a model with 209 free scalar parameters with only 178 data points will result in a degenerate solution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(algorithm='viterbi', init_params='ste', n_components=10,\n",
       "               n_iter=10, params='ste',\n",
       "               random_state=RandomState(MT19937) at 0x261FF098570,\n",
       "               startprob_prior=1.0, tol=0.01, transmat_prior=1.0,\n",
       "               verbose=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess training data for specific HMM\n",
    "# Choose a music template\n",
    "fname = 'twinkle-twinkle-little-star'\n",
    "min_note = 1024\n",
    "\n",
    "# load music from midi file\n",
    "dir_path = './data/'\n",
    "filepath = os.path.join(dir_path,fname+'.csv')\n",
    "music = pre_process(filepath,min_note)\n",
    "\n",
    "# Obtain all components of a midi piano file\n",
    "quarter_note, num, denom, key, measures, time, \\\n",
    "            tr_notes_specific, velocity, song, ind = music.read_process()\n",
    "possibleVelocities =  np.unique(velocity)\n",
    "\n",
    "# Preprocess training data for generic HMM\n",
    "pickle_file_path = r\".\\JSB_Chorales.pickle\"\n",
    "file = open(pickle_file_path, 'rb')\n",
    "dataset = pickle.load(file)\n",
    "file.close()\n",
    "tr_notes_generic = get_training_notes(dataset)\n",
    "\n",
    "\n",
    "possibleNotes = np.unique(np.concatenate([tr_notes_generic, tr_notes_specific]))\n",
    "\n",
    "n = len(tr_notes_specific)\n",
    "states = 10\n",
    "\n",
    "# Train specific HMM\n",
    "led_specific = LabelEncoderDecoder(tr_notes_specific)\n",
    "model_specific = hmm.MultinomialHMM(n_components=states)\n",
    "xNotes_specific = led_specific.encode(tr_notes_specific)\n",
    "observ_data_specific = xNotes_specific.reshape(len(tr_notes_specific),1)\n",
    "model_specific.fit(observ_data_specific)\n",
    "\n",
    "# Train generic HMM\n",
    "led_generic = LabelEncoderDecoder(tr_notes_generic)\n",
    "model_generic = hmm.MultinomialHMM(n_components=states)\n",
    "xNotes_generic = led_generic.encode(tr_notes_generic)\n",
    "observ_data_generic = xNotes_generic.reshape(len(xNotes_generic),1)\n",
    "model_generic.fit(observ_data_generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 52)\n"
     ]
    }
   ],
   "source": [
    "# Interpolation\n",
    "led = LabelEncoderDecoder(possibleNotes)\n",
    "leds = [led_specific, led_generic, led]\n",
    "newNotes = led.decode(generate_output_interpolate(model_specific, model_generic, len(tr_notes_specific), 0.5, leds))\n",
    "newVelocities = find_vel(newNotes, velocity, gp = False)\n",
    "\n",
    "# Output music into csv \n",
    "output_filename = dir_path+fname+'_hmm_interpolate'+str(states)+'.csv'\n",
    "output_music_csv(output_filename, time, newNotes.astype(int),newVelocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to Midi\n",
    "with open(output_filename, \"r\") as f:\n",
    "    midi_object = py_midicsv.csv_to_midi(f.readlines())\n",
    "\n",
    "# Save the parsed MIDI file to disk\n",
    "with open(dir_path+fname+'_hmm_interpolate'+str(states)+\".midi\", \"wb\") as output_file:\n",
    "    midi_writer = py_midicsv.FileWriter(output_file)\n",
    "    midi_writer.write(midi_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc401",
   "language": "python",
   "name": "csc401"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
